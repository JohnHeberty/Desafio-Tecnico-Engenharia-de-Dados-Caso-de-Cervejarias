---

# Desafio TÃ©cnico â€“ Engenharia de Dados ğŸ»

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para o desafio tÃ©cnico de Engenharia de Dados, com foco na ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados sobre cervejarias utilizando a API [Open Brewery DB](https://api.openbrewerydb.org/breweries).

## ğŸ“Œ Objetivo

Construir um pipeline de dados utilizando Python, orquestrado com uma ferramenta Ã  sua escolha, seguindo a **arquitetura de data lake em camadas (medalhÃ£o)**:

- **Camada Bronze:** dados brutos da API.
- **Camada Prata:** dados transformados em formato colunar e particionados por localizaÃ§Ã£o.
- **Camada Ouro:** visÃ£o analÃ­tica com agregaÃ§Ãµes por tipo e localizaÃ§Ã£o de cervejarias.

---

## ğŸ”§ Stack Utilizada

- **Linguagem:** Python
- **OrquestraÃ§Ã£o:** [Airflow / Luigi / Mage / etc.] <!-- Edite conforme sua escolha -->
- **Processamento:** [PySpark / Pandas / etc.] <!-- Edite conforme sua escolha -->
- **Armazenamento:** Arquivos em formato Parquet / Delta Lake
- **ContainerizaÃ§Ã£o:** Docker / Kubernetes (opcional, mas recomendÃ¡vel)

---

## ğŸš€ Pipeline de Dados

1. **IngestÃ£o (Camada Bronze):**
   - Dados sÃ£o consumidos da API pÃºblica Open Brewery DB.
   - PersistÃªncia dos dados brutos no data lake.

2. **TransformaÃ§Ã£o (Camada Prata):**
   - ConversÃ£o dos dados para formato colunar (Parquet ou Delta).
   - Particionamento por localizaÃ§Ã£o (estado ou cidade).
   - AplicaÃ§Ã£o de limpezas e validaÃ§Ãµes.

3. **AgregaÃ§Ã£o (Camada Ouro):**
   - CriaÃ§Ã£o de uma visÃ£o analÃ­tica com o nÃºmero de cervejarias por tipo e localizaÃ§Ã£o.

---

## âš ï¸ Monitoramento e Alertas

O pipeline inclui estratÃ©gias para:
- Tentativas automÃ¡ticas em caso de falhas.
- ValidaÃ§Ã£o de qualidade dos dados.
- Logs estruturados.
- Alertas (e-mail, Slack, etc.) em caso de falhas ou dados inconsistentes.

---

## ğŸ§ª Testes

Inclui casos de teste para as principais funÃ§Ãµes de transformaÃ§Ã£o e ingestÃ£o de dados utilizando `pytest`.

---

## ğŸ³ ContainerizaÃ§Ã£o (opcional)

A soluÃ§Ã£o pode ser executada em ambiente containerizado via Docker:

```bash
docker-compose up --build
```

---

## â˜ï¸ ServiÃ§os em Nuvem (opcional)

Caso deseje utilizar serviÃ§os em nuvem (S3, GCP, Azure Data Lake etc.), certifique-se de:
- Configurar as credenciais localmente (nÃ£o envie para o GitHub).
- InstruÃ§Ãµes detalhadas estarÃ£o disponÃ­veis no diretÃ³rio `docs/`.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ dags/                   # Pipelines do Airflow (ou scripts do orquestrador)
â”œâ”€â”€ src/                    # CÃ³digo-fonte e transformaÃ§Ãµes
â”œâ”€â”€ tests/                  # Casos de teste
â”œâ”€â”€ data/                   # Camadas do data lake (bronze, prata, ouro)
â”œâ”€â”€ docker/                 # Dockerfile e configs (se aplicÃ¡vel)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âœ… CritÃ©rios Avaliados

- Qualidade do cÃ³digo
- Clareza na arquitetura
- EficiÃªncia do pipeline
- DocumentaÃ§Ã£o
- Tratamento de erros
- Monitoramento

---

## ğŸ“… Prazo

O desafio deve ser entregue em atÃ© **1 semana** a partir da data de recebimento.

---

## ğŸ’¬ Contato

DÃºvidas ou sugestÃµes? Fique Ã  vontade para abrir uma issue ou entrar em contato.

---